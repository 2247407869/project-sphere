#!/usr/bin/env python3
"""
Graphiti MCP Server - è€å¼ APIç‰ˆæœ¬

åŸºäºå®˜æ–¹Graphitiæ¡†æ¶çš„MCPæœåŠ¡å™¨å®ç°ï¼Œä½¿ç”¨è€å¼ API
æ”¯æŒEpisodeç®¡ç†ã€æœç´¢å’ŒåŸºæœ¬çš„çŸ¥è¯†å›¾è°±æ“ä½œ
è€å¼ APIåŸç”Ÿæ”¯æŒOpenAI Responses APIï¼Œæ— éœ€ä»£ç†è½¬æ¢
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Sequence

import uvicorn
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from dotenv import load_dotenv

# å°è¯•å¯¼å…¥Graphitiå’ŒOpenAIå®¢æˆ·ç«¯
try:
    from graphiti_core import Graphiti
    from graphiti_core.nodes import EpisodeType
    from graphiti_core.driver.falkordb_driver import FalkorDriver
    from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient
    from graphiti_core.llm_client.config import LLMConfig
    from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
    GRAPHITI_AVAILABLE = True
    LAOZHANG_AVAILABLE = True
except ImportError as e:
    GRAPHITI_AVAILABLE = False
    LAOZHANG_AVAILABLE = False
    print(f"âš ï¸  Graphitiæˆ–è€å¼ APIå®¢æˆ·ç«¯æœªå®‰è£…: {e}")
    print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
log_level = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(
    level=getattr(logging, log_level, logging.INFO),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("GraphitiMCP")

# é…ç½®
class Config:
    # è€å¼ APIé…ç½®ï¼ˆç”¨äºLLMæ¨ç†å’ŒåµŒå…¥ï¼‰
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.laozhang.ai/v1")
    MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")
    SMALL_MODEL_NAME = os.getenv("SMALL_MODEL_NAME", os.getenv("MODEL_NAME", "gpt-4o-mini"))
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")
    
    # æ•°æ®åº“é…ç½®
    REDIS_HOST = os.getenv("REDIS_HOST", "localhost")
    REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
    REDIS_PASSWORD = os.getenv("REDIS_PASSWORD", "")
    
    # Graphitié…ç½®
    GRAPHITI_GROUP_ID = os.getenv("GRAPHITI_GROUP_ID", "demo")
    SEMAPHORE_LIMIT = int(os.getenv("SEMAPHORE_LIMIT", "5"))
    
    # æœåŠ¡å™¨é…ç½®
    HOST = "0.0.0.0"
    PORT = 8000

# MCPè¯·æ±‚/å“åº”æ¨¡å‹
class MCPRequest(BaseModel):
    method: str
    params: Dict[str, Any]

class MCPResponse(BaseModel):
    result: Optional[Any] = None
    error: Optional[Dict[str, Any]] = None

class ToolCallRequest(BaseModel):
    name: str
    arguments: Dict[str, Any]

# GraphitiåŒ…è£…å™¨
class GraphitiWrapper:
    def __init__(self):
        self.graphiti = None
        self.driver = None  # æ˜¾å¼å­˜å‚¨é©±åŠ¨
        self.episodes = []  # æ¨¡æ‹Ÿå­˜å‚¨
        
    async def initialize(self):
        """åˆå§‹åŒ–Graphitiè¿æ¥"""
        if not GRAPHITI_AVAILABLE or not LAOZHANG_AVAILABLE:
            logger.warning("Graphitiæˆ–è€å¼ APIä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            return True
            
        if not Config.OPENAI_API_KEY:
            logger.error("âŒ æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
            return False
            
        try:
            # ä½¿ç”¨FalkorDriverè¿æ¥FalkorDB
            falkor_driver = FalkorDriver(
                host=Config.REDIS_HOST,
                port=Config.REDIS_PORT,
                username="default" if Config.REDIS_PASSWORD else None,
                password=Config.REDIS_PASSWORD if Config.REDIS_PASSWORD else None
            )
            
            logger.info(f"ğŸš€ åˆå§‹åŒ–æ¨¡å‹: LLM={Config.MODEL_NAME}, Embedding={Config.EMBEDDING_MODEL}")
            logger.info(f"ğŸ”— API Endpoint: {Config.OPENAI_BASE_URL}")
            
            # ä½¿ç”¨ OpenAIGenericClient ä»¥è·å¾—æ›´å¥½çš„ç¬¬ä¸‰æ–¹ API å…¼å®¹æ€§ (DeepSeek)
            self.graphiti = Graphiti(
                graph_driver=falkor_driver,
                llm_client=OpenAIGenericClient( # Changed from OpenAIClient to OpenAIGenericClient
                    config=LLMConfig(
                        api_key=Config.OPENAI_API_KEY,
                        model=Config.MODEL_NAME,
                        small_model=Config.SMALL_MODEL_NAME,
                        base_url=Config.OPENAI_BASE_URL
                    )
                ),
                embedder=OpenAIEmbedder(
                    config=OpenAIEmbedderConfig(
                        api_key=Config.OPENAI_API_KEY,
                        embedding_model=Config.EMBEDDING_MODEL,
                        base_url=Config.OPENAI_BASE_URL
                    )
                )
                # ç§»é™¤cross_encoderï¼Œä½¿ç”¨é»˜è®¤çš„å‘é‡ç›¸ä¼¼åº¦æ’åº
            )
            self.driver = falkor_driver  # å­˜å‚¨å¼•ç”¨
            
            # æ„å»ºç´¢å¼•å’Œçº¦æŸ
            await self.graphiti.build_indices_and_constraints()
            logger.info("âœ… Graphitiåˆå§‹åŒ–æˆåŠŸï¼ˆè€å¼ APIç›´è¿ï¼‰")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Graphitiåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def add_episode(self, name: str, episode_body: str, episode_type: str = "text", 
                          source_description: str = "User input", reference_time: Optional[str] = None) -> Dict[str, Any]:
        """æ·»åŠ Episodeåˆ°çŸ¥è¯†å›¾è°±"""
        if not self.graphiti:
            return {
                "success": False,
                "message": "Graphitiæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼",
                "episode_id": f"sim_{datetime.now().timestamp()}",
                "name": name,
                "content": episode_body
            }
            
        try:
            # è§£æå‚è€ƒæ—¶é—´
            ref_time = None
            if reference_time:
                try:
                    ref_time = datetime.fromisoformat(reference_time.replace('Z', '+00:00'))
                except ValueError:
                    ref_time = datetime.now(timezone.utc)
            else:
                ref_time = datetime.now(timezone.utc)
            
            # ç¡®å®šEpisodeç±»å‹
            ep_type = EpisodeType.text
            if episode_type.lower() == "message":
                ep_type = EpisodeType.message
            elif episode_type.lower() == "observation":
                ep_type = EpisodeType.observation
            
            # æ·»åŠ Episode
            result = await self.graphiti.add_episode(
                name=name,
                episode_body=episode_body,
                source=ep_type,  # ä½¿ç”¨ source å‚æ•°è€Œä¸æ˜¯ episode_type
                source_description=source_description,
                reference_time=ref_time,
                group_id=Config.GRAPHITI_GROUP_ID
            )
            
            logger.info(f"âœ… æˆåŠŸæ·»åŠ Episode: {name}")
            
            # å°†AddEpisodeResultså¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
            episode_uuid = None
            if hasattr(result, 'episode') and result.episode:
                episode_uuid = str(result.episode.uuid) if hasattr(result.episode, 'uuid') else None
            
            return {
                "success": True,
                "message": "Episodeæ·»åŠ æˆåŠŸ",
                "episode_id": episode_uuid,
                "name": name,
                "content": episode_body,
                "episode_type": episode_type,
                "source_description": source_description,
                "reference_time": ref_time.isoformat() if ref_time else None,
                "group_id": Config.GRAPHITI_GROUP_ID,
                "created_nodes": len(result.nodes) if hasattr(result, 'nodes') else 0,
                "created_edges": len(result.edges) if hasattr(result, 'edges') else 0
            }
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ Episodeå¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"æ·»åŠ Episodeå¤±è´¥: {str(e)}",
                "error": str(e)
            }
    
    async def search_episodes(self, query: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢Episodes - æ”¹è¿›ç‰ˆæœ¬ï¼Œæä¾›æ›´å‹å¥½çš„ç”¨æˆ·ä½“éªŒ"""
        logger.info(f"ğŸ” æ­£åœ¨æœç´¢è®°å¿†: query='{query}', limit={num_results}")
        try:
            if self.graphiti:
                # ä½¿ç”¨çœŸå®Graphitiæœç´¢
                results = await self.graphiti.search(
                    query=query,
                    num_results=num_results,
                    group_ids=[Config.GRAPHITI_GROUP_ID]
                )
                logger.info(f"ğŸ“Š Graphitiæœç´¢è¿”å›äº† {len(results)} æ¡åŸå§‹ç»“æœ")
                
                logger.info(f"ğŸ“Š Graphitiæœç´¢è¿”å›äº† {len(results)} æ¡ç»“æœ")

                # å¦‚æœæœç´¢ç»“æœä¸ºç©ºï¼Œå°è¯•é€šè¿‡ Cypher è¿›è¡Œç®€å•çš„å…³é”®è¯æ£€ç´¢ä½œä¸ºå…œåº•
                if not results and self.driver:
                    logger.info(f"ğŸ” è¯­ä¹‰æœç´¢æ— ç»“æœï¼Œå°è¯• Cypher å…³é”®è¯æ£€ç´¢: {query}")
                    try:
                        # ç®€å•çš„å…³é”®è¯åŒ¹é…
                        cypher = f"MATCH (n:Episodic) WHERE n.group_id = '{Config.GRAPHITI_GROUP_ID}' AND (n.content CONTAINS '{query}' OR n.name CONTAINS '{query}') RETURN n LIMIT {num_results}"
                        results = await self.driver.execute_query(cypher)
                        logger.info(f"å…œåº• Cypher æ£€ç´¢è¿”å›äº† {len(results)} æ¡ç»“æœ")
                    except Exception as e:
                        logger.warning(f"å…œåº• Cypher æ£€ç´¢ä¹Ÿå¤±è´¥äº†: {e}")
                
                formatted_results = []
                for result in results:
                    # execute_query å¯èƒ½è¿”å› [node] åˆ—è¡¨
                    actual_item = result[0] if isinstance(result, (list, tuple)) else result
                    
                    # ç¡®å®šå±æ€§å­—å…¸
                    props = {}
                    if hasattr(actual_item, 'properties'):
                        props = actual_item.properties
                    elif isinstance(actual_item, dict):
                        props = actual_item
                    else:
                        for attr in ['uuid', 'name', 'content', 'fact', 'score', 'created_at', 'source_description']:
                            if hasattr(actual_item, attr):
                                props[attr] = getattr(actual_item, attr)

                    # æ£€æŸ¥ç»“æœç±»å‹å¹¶ç›¸åº”å¤„ç†
                    if props.get('content') and not props.get('fact'):
                        # è¿™æ˜¯ä¸€ä¸ªEpisodeèŠ‚ç‚¹ - åŸå§‹è®°å¿†å†…å®¹
                        formatted_result = {
                            "id": str(props.get('uuid', 'unknown')),
                            "name": props.get('name', 'Unnamed'),
                            "content": props.get('content', ''),
                            "score": float(props.get('score', 1.0)),
                            "created_at": props.get('created_at', datetime.now().isoformat()),
                            "episode_type": "episode",
                            "source_description": props.get('source_description', 'Original Memory'),
                            "content_type": "åŸå§‹è®°å¿†"
                        }
                    elif props.get('fact'):
                        # è¿™æ˜¯ä¸€ä¸ªEdgeå¯¹è±¡ï¼ŒåŒ…å«äº‹å®ä¿¡æ¯ - ç»“æ„åŒ–çŸ¥è¯†
                        fact_content = props.get('fact', '')
                        edge_name = props.get('name', 'UNKNOWN')
                        
                        # æ ¹æ®Edgeç±»å‹æä¾›æ›´å‹å¥½çš„æè¿°
                        user_friendly_content = f"çŸ¥è¯†å…³ç³»({edge_name})ï¼š{fact_content}"
                        
                        formatted_result = {
                            "id": str(props.get('uuid', 'unknown')),
                            "name": edge_name,
                            "content": user_friendly_content,
                            "score": float(props.get('score', 1.0)),
                            "created_at": props.get('created_at', datetime.now().isoformat()),
                            "episode_type": "knowledge",
                            "source_description": "ç»“æ„åŒ–çŸ¥è¯†",
                            "content_type": "çŸ¥è¯†å…³ç³»",
                            "raw_fact": fact_content
                        }
                    else:
                        # é€šç”¨å¤„ç†
                        formatted_result = {
                            "id": str(props.get('uuid', 'unknown')),
                            "name": props.get('name', 'Unnamed'),
                            "content": str(actual_item)[:200] + "..." if len(str(actual_item)) > 200 else str(actual_item),
                            "score": float(props.get('score', 1.0)),
                            "created_at": props.get('created_at', datetime.now().isoformat()),
                            "episode_type": "unknown",
                            "source_description": "Unknown",
                            "content_type": "æœªçŸ¥ç±»å‹"
                        }
                    
                    # æ ¼å¼åŒ–æ—¥æœŸ
                    created_at = props.get('created_at')
                    if hasattr(created_at, 'isoformat'):
                        formatted_result["created_at"] = created_at.isoformat()
                    
                    formatted_results.append(formatted_result)
                
                # æŒ‰ç›¸å…³æ€§å’Œç±»å‹æ’åºï¼šEpisodeä¼˜å…ˆï¼Œç„¶åæ˜¯Edge
                formatted_results.sort(key=lambda x: (
                    0 if x['episode_type'] == 'episode' else 1,  # Episodeä¼˜å…ˆ
                    -x['score']  # é«˜åˆ†ä¼˜å…ˆ
                ))
                
                logger.info(f"âœ… æœç´¢å®Œæˆï¼Œæœ€ç»ˆæ‰¾åˆ° {len(formatted_results)} ä¸ªç»“æœ")
                return formatted_results
            else:
                # æ¨¡æ‹Ÿæœç´¢
                results = []
                for episode in self.episodes:
                    if query.lower() in episode['content'].lower() or query.lower() in episode['name'].lower():
                        results.append({
                            "id": episode['id'],
                            "name": episode['name'],
                            "content": episode['content'],
                            "score": 0.8,
                            "created_at": episode['created_at'],
                            "episode_type": episode.get('type', 'text'),
                            "source_description": episode.get('source', 'MCP')
                        })
                return results[:num_results]
                
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    async def get_episodes(self, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–Episodesåˆ—è¡¨"""
        try:
            if self.graphiti:
                try:
                    # é¦–å…ˆå°è¯•å®˜æ–¹ API
                    nodes = await self.graphiti.retrieve_episodes(
                        reference_time=datetime.now(timezone.utc),
                        last_n=limit,
                        group_ids=[Config.GRAPHITI_GROUP_ID]
                    )
                    logger.info(f"API retrieve_episodes è¿”å›äº† {len(nodes)} ä¸ªç»“æœ")
                except Exception as e:
                    logger.warning(f"API retrieve_episodes å¤±è´¥ï¼Œå°è¯•åŸç”Ÿ Cypher: {e}")
                    nodes = []

                # å¦‚æœå®˜æ–¹ API è¿”å›ç©ºï¼Œä½¿ç”¨åŸç”Ÿ Cypher å…œåº• (é’ˆå¯¹æŸäº›ç‰ˆæœ¬çš„ FalkorDB å…¼å®¹æ€§)
                if not nodes and self.driver:
                    try:
                        cypher = f"MATCH (n:Episodic) WHERE n.group_id = '{Config.GRAPHITI_GROUP_ID}' RETURN n ORDER BY n.created_at DESC LIMIT {limit}"
                        nodes = await self.driver.execute_query(cypher)
                        logger.info(f"åŸç”Ÿ Cypher è¿”å›äº† {len(nodes)} ä¸ªç»“æœ")
                    except Exception as e:
                        logger.error(f"åŸç”Ÿ Cypher å…œåº•ä¹Ÿå¤±è´¥äº†: {e}")
                        nodes = []
                
                formatted_results = []
                for node in nodes:
                    # execute_query è¿”å›çš„ç»“æœç»“æ„å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œéœ€è¦å…¼å®¹æ€§å¤„ç†
                    # å¦‚æœæ˜¯ list (row)ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                    actual_node = node[0] if isinstance(node, (list, tuple)) else node
                    
                    # ç¡®å®šå±æ€§å­—å…¸
                    props = {}
                    if hasattr(actual_node, 'properties'):
                        props = actual_node.properties
                    elif isinstance(actual_node, dict):
                        props = actual_node
                    else:
                        # å°è¯•é€šè¿‡ getattr è·å–å¸¸è§å±æ€§
                        for attr in ['uuid', 'name', 'content', 'created_at', 'source_description']:
                            if hasattr(actual_node, attr):
                                props[attr] = getattr(actual_node, attr)

                    formatted_result = {
                        "id": str(props.get('uuid', 'unknown')),
                        "name": props.get('name', 'Unnamed'),
                        "content": props.get('content', ''),
                        "score": 1.0,
                        "created_at": props.get('created_at', datetime.now(timezone.utc).isoformat()),
                        "episode_type": "episode",
                        "source_description": props.get('source_description', 'Original Memory'),
                        "content_type": "åŸå§‹è®°å¿†"
                    }
                    
                    # æ ¼å¼åŒ–æ—¥æœŸ
                    created_at = props.get('created_at')
                    if hasattr(created_at, 'isoformat'):
                        formatted_result["created_at"] = created_at.isoformat()
                    elif isinstance(created_at, str):
                        formatted_result["created_at"] = created_at
                        
                    formatted_results.append(formatted_result)
                
                logger.info(f"âœ… æœ€ç»ˆè·å–åˆ° {len(formatted_results)} ä¸ªEpisode")
                return formatted_results
            else:
                # æ¨¡æ‹Ÿæ¨¡å¼
                return self.episodes[-limit:]
                
        except Exception as e:
            logger.error(f"è·å–Episodeså¤±è´¥: {e}")
            return []
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.graphiti:
            await self.graphiti.close()

# å…¨å±€Graphitiå®ä¾‹
graphiti_wrapper = GraphitiWrapper()

# FastAPIåº”ç”¨
app = FastAPI(
    title="Graphiti MCP Server",
    description="GraphitiçŸ¥è¯†å›¾è°±çš„MCPåè®®æœåŠ¡å™¨ï¼ˆè€å¼ APIç‰ˆæœ¬ï¼‰",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    logger.info("ğŸš€ å¯åŠ¨Graphiti MCPæœåŠ¡å™¨ï¼ˆè€å¼ APIç‰ˆæœ¬ï¼‰...")
    await graphiti_wrapper.initialize()

@app.on_event("shutdown")
async def shutdown_event():
    """å…³é—­æ—¶æ¸…ç†"""
    logger.info("ğŸ›‘ å…³é—­Graphiti MCPæœåŠ¡å™¨...")
    await graphiti_wrapper.close()

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "Graphiti MCP Server (è€å¼ API)",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "graphiti_available": GRAPHITI_AVAILABLE,
        "laozhang_available": LAOZHANG_AVAILABLE,
        "mode": "real" if graphiti_wrapper.graphiti else "simulation",
        "laozhang_configured": bool(Config.OPENAI_API_KEY),
        "direct_connection": True,
        "api_provider": "è€å¼ API"
    }

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "service": "Graphiti MCP Server (è€å¼ API)",
        "version": "1.0.0",
        "endpoints": {
            "health": "/health",
            "tools": "/tools/list",
            "call": "/tools/call"
        }
    }

@app.get("/tools/list")
async def list_tools():
    """åˆ—å‡ºå¯ç”¨å·¥å…·"""
    tools = [
        {
            "name": "add_episode",
            "description": "å‘çŸ¥è¯†å›¾è°±æ·»åŠ ä¸€ä¸ªEpisodeï¼ˆè®°å¿†ç‰‡æ®µï¼‰",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "name": {"type": "string", "description": "Episodeåç§°"},
                    "episode_body": {"type": "string", "description": "Episodeå†…å®¹"},
                    "episode_type": {"type": "string", "description": "Episodeç±»å‹", "default": "text"},
                    "source_description": {"type": "string", "description": "æ¥æºæè¿°", "default": "MCP"}
                },
                "required": ["name", "episode_body"]
            }
        },
        {
            "name": "search",
            "description": "æœç´¢çŸ¥è¯†å›¾è°±ä¸­çš„Episodes",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "æœç´¢æŸ¥è¯¢"},
                    "num_results": {"type": "integer", "description": "è¿”å›ç»“æœæ•°é‡", "default": 5}
                },
                "required": ["query"]
            }
        },
        {
            "name": "get_episodes",
            "description": "è·å–Episodesåˆ—è¡¨",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "limit": {"type": "integer", "description": "è¿”å›æ•°é‡é™åˆ¶", "default": 100}
                }
            }
        }
    ]
    
    return {"tools": tools}

@app.post("/tools/call")
async def call_tool(request: ToolCallRequest):
    """è°ƒç”¨å·¥å…·"""
    try:
        tool_name = request.name
        args = request.arguments
        
        if tool_name == "add_episode":
            result = await graphiti_wrapper.add_episode(
                name=args.get("name", "Unnamed Episode"),
                episode_body=args.get("episode_body", ""),
                episode_type=args.get("episode_type", "text"),
                source_description=args.get("source_description", "MCP")
            )
            return {"result": result}
            
        elif tool_name == "search":
            results = await graphiti_wrapper.search_episodes(
                query=args.get("query", ""),
                num_results=args.get("num_results", 5)
            )
            return {"result": results}
            
        elif tool_name == "get_episodes":
            episodes = await graphiti_wrapper.get_episodes(
                limit=args.get("limit", 100)
            )
            return {"result": episodes}
            
        else:
            raise HTTPException(status_code=400, detail=f"æœªçŸ¥å·¥å…·: {tool_name}")
            
    except Exception as e:
        logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
        return {"error": {"code": -1, "message": str(e)}}

# MCPåè®®å…¼å®¹ç«¯ç‚¹
@app.post("/mcp")
async def mcp_endpoint(request: MCPRequest):
    """MCPåè®®ç«¯ç‚¹"""
    try:
        if request.method == "tools/list":
            tools_response = await list_tools()
            return MCPResponse(result=tools_response["tools"])
            
        elif request.method == "tools/call":
            tool_request = ToolCallRequest(
                name=request.params.get("name"),
                arguments=request.params.get("arguments", {})
            )
            call_response = await call_tool(tool_request)
            return MCPResponse(result=call_response.get("result"), error=call_response.get("error"))
            
        else:
            return MCPResponse(error={"code": -1, "message": f"æœªçŸ¥æ–¹æ³•: {request.method}"})
            
    except Exception as e:
        logger.error(f"MCPè¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        return MCPResponse(error={"code": -1, "message": str(e)})

@app.api_route("/mcp/stream", methods=["GET", "POST"])
async def mcp_stream_endpoint(request: Request):
    """MCPæµå¼åè®®ç«¯ç‚¹ - å…¼å®¹LobeChat"""
    # å¤„ç†GETè¯·æ±‚ - è¿”å›Manifest
    if request.method == "GET":
        logger.info("ğŸ“¥ MCP Stream Probe (GET) - Returning Manifest")
        return await mcp_manifest_get()

    try:
        # è§£æè¯·æ±‚ä½“
        body = await request.json()
        logger.info(f"ğŸ“¥ MCP Stream Request: {json.dumps(body, ensure_ascii=False)}")
        
        # å¤„ç†ä¸åŒçš„MCPæ–¹æ³•
        if body.get("method") == "initialize":
            # åˆå§‹åŒ–å“åº”
            return {
                "jsonrpc": "2.0",
                "id": body.get("id"),
                "result": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {
                        "tools": {}
                    },
                    "serverInfo": {
                        "name": "graphiti-memory",
                        "version": "1.0.0",
                        "description": "GraphitiçŸ¥è¯†å›¾è°±è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆè€å¼ APIç‰ˆæœ¬ï¼‰"
                    }
                }
            }
        
        elif body.get("method") == "tools/list":
            # å·¥å…·åˆ—è¡¨
            tools_response = await list_tools()
            return {
                "jsonrpc": "2.0",
                "id": body.get("id"),
                "result": {
                    "tools": tools_response["tools"]
                }
            }
        
        elif body.get("method") == "tools/call":
            # å·¥å…·è°ƒç”¨
            params = body.get("params", {})
            tool_request = ToolCallRequest(
                name=params.get("name"),
                arguments=params.get("arguments", {})
            )
            call_response = await call_tool(tool_request)
            
            # MCPå·¥å…·è°ƒç”¨å“åº”æ ¼å¼ - ç›´æ¥è¿”å›å·¥å…·ç»“æœ
            if "result" in call_response:
                # å°†ç»“æœè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œä¾¿äºLobeChatæ˜¾ç¤º
                result_data = call_response["result"]
                if isinstance(result_data, (dict, list)):
                    result_text = json.dumps(result_data, ensure_ascii=False, indent=2)
                else:
                    result_text = str(result_data)
                
                return {
                    "jsonrpc": "2.0",
                    "id": body.get("id"),
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": result_text
                            }
                        ]
                    }
                }
            elif "error" in call_response:
                return {
                    "jsonrpc": "2.0",
                    "id": body.get("id"),
                    "error": call_response["error"]
                }
            else:
                return {
                    "jsonrpc": "2.0",
                    "id": body.get("id"),
                    "error": {
                        "code": -32603,
                        "message": "Internal error: Invalid response format"
                    }
                }
        
        else:
            return {
                "jsonrpc": "2.0",
                "id": body.get("id"),
                "error": {
                    "code": -32601,
                    "message": f"Method not found: {body.get('method')}"
                }
            }
            
    except Exception as e:
        logger.error(f"MCPæµå¼è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
        return {
            "jsonrpc": "2.0",
            "id": body.get("id") if 'body' in locals() else None,
            "error": {
                "code": -32603,
                "message": str(e)
            }
        }

@app.get("/mcp/capabilities")
async def mcp_capabilities():
    """MCPèƒ½åŠ›æŸ¥è¯¢ç«¯ç‚¹"""
    return {
        "protocolVersion": "2024-11-05",
        "capabilities": {
            "tools": {}
        },
        "serverInfo": {
            "name": "graphiti-memory",
            "version": "1.0.0",
            "description": "GraphitiçŸ¥è¯†å›¾è°±è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆDeepSeekç‰ˆæœ¬ï¼‰"
        }
    }

@app.get("/mcp/manifest")
async def mcp_manifest_get():
    """MCP Manifestç«¯ç‚¹ - GETè¯·æ±‚ï¼ˆç›´æ¥è¿”å›manifestï¼‰"""
    tools = await list_tools()
    return {
        "name": "graphiti-memory",
        "version": "1.0.0",
        "description": "GraphitiçŸ¥è¯†å›¾è°±è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆSiliconFlowç‰ˆæœ¬ï¼‰",
        "author": "Graphiti Demo",
        "homepage": "http://localhost:3000",
        "repository": "https://github.com/getzep/graphiti",
        "capabilities": {
            "tools": {}
        },
        "tools": tools["tools"],
        "serverInfo": {
            "name": "graphiti-memory",
            "version": "1.0.0"
        }
    }

@app.post("/mcp/manifest")
async def mcp_manifest_post(request: Request):
    """MCP Manifestç«¯ç‚¹ - POSTè¯·æ±‚ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
    try:
        # å°è¯•è§£æè¯·æ±‚ä½“
        try:
            body = await request.json()
        except:
            body = {}
        
        tools = await list_tools()
        manifest = {
            "name": "graphiti-memory",
            "version": "1.0.0",
            "description": "GraphitiçŸ¥è¯†å›¾è°±è®°å¿†ç®¡ç†æœåŠ¡ï¼ˆSiliconFlowç‰ˆæœ¬ï¼‰",
            "author": "Graphiti Demo",
            "homepage": "http://localhost:3000",
            "repository": "https://github.com/getzep/graphiti",
            "capabilities": {
                "tools": {}
            },
            "tools": tools["tools"],
            "serverInfo": {
                "name": "graphiti-memory",
                "version": "1.0.0"
            }
        }
        
        # å¦‚æœæ˜¯JSON-RPCè¯·æ±‚ï¼Œè¿”å›JSON-RPCæ ¼å¼
        if isinstance(body, dict) and "jsonrpc" in body:
            return {
                "jsonrpc": "2.0",
                "id": body.get("id"),
                "result": manifest
            }
        else:
            # å¦åˆ™ç›´æ¥è¿”å›manifest
            return manifest
            
    except Exception as e:
        logger.error(f"Manifestè¯·æ±‚å¤±è´¥: {e}")
        # å°è¯•è¿”å›JSON-RPCé”™è¯¯æ ¼å¼
        try:
            body = await request.json()
            if isinstance(body, dict) and "jsonrpc" in body:
                return {
                    "jsonrpc": "2.0",
                    "id": body.get("id"),
                    "error": {
                        "code": -1,
                        "message": str(e)
                    }
                }
        except:
            pass
        
        raise HTTPException(status_code=500, detail=str(e))

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Graphiti MCP Server (è€å¼ API)")
    parser.add_argument("--host", default=Config.HOST, help="æœåŠ¡å™¨ä¸»æœº")
    parser.add_argument("--port", type=int, default=Config.PORT, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--transport", default="sse", help="ä¼ è¾“åè®®")
    
    args = parser.parse_args()
    
    logger.info(f"å¯åŠ¨Graphiti MCPæœåŠ¡å™¨ï¼ˆè€å¼ APIç‰ˆæœ¬ï¼‰ {args.host}:{args.port}")
    
    uvicorn.run(
        "graphiti_mcp_server:app",
        host=args.host,
        port=args.port,
        reload=False,
        log_level="info"
    )

if __name__ == "__main__":
    main()